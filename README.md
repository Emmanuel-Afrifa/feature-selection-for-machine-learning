# Feature Selection for Machine Learning

"This repository provides an overview of feature selection in machine learning


## Tool Used
I used the Python programming language (version 3.10.8) to carry out this project. In particular, I use the following libraries:
- Numpy (1.26.2): For numerical computations.
- Pandas (2.1.4): For the Dataframe and some analysis thereof.
- Matplotlib (3.8.2): For visualizations
- Seaborn (0.13.0): For visualizations
- Scikit-Learn (1.4.0): For data preprocessing, model building and metrics checking.


## Procedure
- Explored the data
- Split the data into training and test sets
- Encoded categorical features
- Standardized numerical features
- used feature selection wrapper and embedded feature selection methods to select the best features
- Trained the a lgsitic regression model and made predictions on the test set


## Data Sources
- [Titanic Dataset](https://www.kaggle.com/competitions/titanic/data)

## References
- [How to Choose a feature selection method for machine learning](https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/)
- [Feature Selection Methods and How to Choose them](https://neptune.ai/blog/feature-selection-methods)
- [Feature Selection Using XGBoost](https://medium.com/@dhanyahari07/feature-selection-using-xgboost-f0622fb70c4d)

## Author
- Emmanuel Afrifa
- [emmaquame9@gmail.com](mailto:emmaquame9@gmail.com)
- [Frontend-Mentor](https://www.frontendmentor.io/profile/Emmanuel-Afrifa)
- [Twitter](https://twitter.com/Emma33712365)
- [Linkedin](https://www.linkedin.com/in/emmanuel-afrifa-840674214/)